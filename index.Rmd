---
title: "Data Challenge"
author: "Jingjing Guo"
date: "Oct 30, 2017"
output:
  #pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Problem 1: Eigenvalues and eigenvectors
1. Explain why the power method returns the largest eigenvalues and its eigenvector
For Matrix $A_{n\times n}$, with eigenvalues $\lambda _1, \lambda _2 ... \lambda _n$ and eigen vectors $v_1, v_2, ... v_n$
$A x = \lambda x$ 
Given any $x_0 = c_1 v_1 + c_2 v_2 + ... c_n v_n$
\begin{align*}
A x_0 &= A(c_1 v_1 + c_2 v_2 + ... c_n v_n) 
= c_1 Av_1 + c_2 Av_2 + ... c_n Av_n 
= c_1 (\lambda_1 v1) + c_2 (\lambda_2 v_2) + ... c_n (\lambda_n v_n)\\
A^2 x_0 &= A [c_1 (\lambda_1 v_1) + c_2 (\lambda_2 v_2) +\ldots + c_n (\lambda_n v_n)]= \lambda_1 c_1 A v_1 + \lambda_2 c_2 A v_2 + \ldots + \lambda_n c_n A v_n \\ & = \lambda_1 c_1 (\lambda_1 v_1) + \lambda_2 c_2 (\lambda_2 v_2) + \ldots + \lambda_n c_n (\lambda_n v_n)\\ &= c_1 (\lambda_1^2 v1) + c_2 (\lambda_2^2 v_2) + ... c_n (\lambda_n^2 v_n)\\
\ldots \\
A^k x_0 &= c_1 (\lambda_1^k v1) + c_2 (\lambda_2^k v_2) + ... c_n (\lambda_n^k v_n) \\ &= \lambda_1^k [c_1 v_1 + c_2 (\frac{\lambda_2}{\lambda_1})^k v_2 + ... c_n (\frac{\lambda_n}{\lambda_1})^k v_n]
\end{align*}
Since $\|\lambda _1\| >\|\lambda _i\|$ $\quad \forall i,\quad$, where $1< i <n $, as $k$ increases,
$A^k x_0 \approx \lambda_1^k c_1 v_1$
The iteration therefore approaches $v_1$ and $c_1$, the largest eigen vector and eigen value.


2. Explain why the condition number of a symmetric matrix is the ratio of its largest and smallest eigenvalues
Answer: 
Condition number measures the relative change of output due to relative change in input (as a result of approximation etc.); it gives bounds of worst case scenario.  For example, solution of $Ax = b$, $x$, changes with  error in $b$,$\delta b$, by $\delta x$, where $A$ is a symmetric matrix, with $\lambda_min < \ldots < \lambda_max$.
i.e. $A(x+\delta x) = b + \delta b$.
Know that $\lVert x \rVert \geq \frac{\lVert b \rVert}{\lambda_{max}}$ and $\lVert \delta x \rVert \geq \frac{\lVert \delta b \rVert}{\lambda_{min}}$
Therefore, the worst case scenario is:
\begin{align*}
	\frac{\lVert \delta x \rVert}{\lVert x \rVert} \leq \frac{\lambda_{max}}{\lambda_{min}} \frac{\lVert \delta b\rVert}{\lVert b \rVert}
\end{align*}
Sensitivity is bounded by $\frac{\lambda_{max}}{\lambda_{min}}$, therefore this value is the condition number.

## Problem 2: Implementing priority queues and sorting
1. Index of the parent node of element i of the vector: $\lfloor \frac{i}{2} \rfloor$
Index of left child node of element i: $2i$
Index of right child node of element i: $2i + 1$

2. write a function of make_heap to return an empty heap
```{r}
make_heap <- function(LMAX) {
  heap0 <- c(rep(NA, LMAX))
  return(heap0)
}
# example:
LMAX <- 10
make_heap(LMAX)
```

3. Write a function to return the max element of the heap:
```{r}
max_heap <- function(heapx){
  max_element <- heapx[1]
  return(max_element)
}
# example
heapx = c(5,2,4,2,1)
max_heap(heapx)
```

4. write a function to remove the max element of the heap
```{r}
removeMax <- function(H){
  sizeNewH <- length(H) - 1
  newH <- H
  maxVal <- H[1]
  newH[1] <- newH[sizeNewH+1]
  newH <- head(newH, -1)

  curPos <- 1
  curLeftChi <- curPos * 2
  curRightChi <- curPos * 2 + 1

  while ( curRightChi <= sizeNewH && newH[curPos] < max(newH[c(curLeftChi, curRightChi)]) ){
    if (newH[curLeftChi] >= newH[curRightChi]){
      temp <- newH[curLeftChi]
      newH[curLeftChi] <- newH[curPos]
      newH[curPos] <- temp
      curPos <- curLeftChi
    }else{
      temp <- newH[curRightChi]
      newH[curRightChi] <- newH[curPos]
      newH[curPos] <- temp
      curPos <- curRightChi
    }
    curLeftChi <- curPos * 2
    curRightChi <- curPos * 2 + 1
  }
  if (curLeftChi==sizeNewH && newH[curPos]<newH[curLeftChi] ){
    temp <- newH[curLeftChi]
    newH[curLeftChi] <- newH[curPos]
    newH[curPos] <- temp
    curPos <- curLeftChi 
  }
  return(newH)
}

H <- c(10,6,9,4,5,8,2)
newH <- removeMax(H)
newH
```

5. Write a function to insert a new element
```{r}
insert <- function(H,num){
  newH <- H
  sizeH <- length(newH)
  newH[sizeH+1] <- num
  curPos <- sizeH + 1
  curPar <- floor(curPos/2)
  while(curPar > 0 && num > newH[curPar]){
    temp <- newH[curPar]
    newH[curPar] <- newH[curPos]
    newH[curPos] <- temp    
    curPos <- curPar
    curPar <- floor(curPos/2)
  }
return(newH)
}

H <- c(10,6,9,4,5,8,2)
insert(H,6)
```

6. Sort 20 random numbers
```{r}
heap_sort <- function(numList){
  N <- length(numList)
  newH <- c()
  sorted_list <- rep(0,N)
  for(num in numList){
    newH <- insert(newH, num)
  }
  i <- 1
  while(i<=N){
    sorted_list[i] <- max_heap(newH)
    newH <- removeMax(newH)
    i <- i + 1
  }
  return(sorted_list)
}

numList <- rnorm(20)
numList
heap_sort(numList)
```


## Problem 3: The Knapsack problem
Write a function:
inputs: weight $w$, value $v$ and capacity $W_knapsack

```{r}
knapsackDP <- function(w,v,W_knapsack){
  N <- length(v)
  Vs <- rep(0,W_knapsack)
  obj_count <- matrix( rep(0,W_knapsack*N), nrow=W_knapsack, ncol=N)
  
  Vs[1] <- max(v[w<=1])
  r <- which.max(v[w<=1])
  obj_count[1,r] <- obj_count[1,r] + 1
  
  for(i in 2:W_knapsack){
    max_check <- rep(0,N)
    combo_i <- matrix(rep(0,N*N), nrow=N, ncol=N)
    for(j in 1:N){
      if(w[j] < i){
        max_check[j] <- Vs[i -w[j]] + v[j]
        combo_i[j,] <- obj_count[(i-w[j]),]
        combo_i[j,j] <- combo_i[j,j] + 1
      }else if (w[j]==i){
        max_check[j] <- v[j]
        combo_i[j,j] <- combo_i[j,j] + 1
      }
    }
    Vs[i] <- max(max_check)
    r <- which.max(max_check)
    max_combo_i <- combo_i[r,]
    obj_count[i,] <- max_combo_i
  }
  
  list2return <- list("max_value" = Vs[W_knapsack], "items" = obj_count[W_knapsack,])
  return(list2return)
}

w = c(1,2,3,4,5,6)
v = c(1,8,10,10,19,25) 
W_knapsack = 25
knapsackDP(w,v,W_knapsack)
```

## Problem 4: Markov Chains
1. $P(S_2=j,S_1=i) = A_{ij}\pi^1_i$

2. $P(S_2=j) = (A \pi^1)_j$

3. $\pi^2 = A \pi^1$

4. $N^2$ multiplications and $N(N-1)$ additions, hence complexity is $O(N^2)$

5. $\pi^t = A^(t-1)*\pi = A*A*A*...*A*\pi$

First we multiply A*pi which is of order O(N^2). 
Then we multiply the outcome by A which is of order $O(N^2)$
Then we multiply the outcome by A which is of order $O(N^2)$
...
Then we multiply the outcome by A which is of order $O(N^2)$

We therefore have $O(N^2)+O(N^2)+...+O(N^2) = t*O(N^2) = O(t*N^2)$

6. $N^T$ sequences


7. summations
(a) how many summations? $N^(t-1)$
(b) To calculate $[P(S_t=1),P(S_t=2),...,P(S_t=N)]$ we need $N^(t-1)+N^(t-1)+...+N^(t-1)=N^t$ additions. Since the elements of this vector sum to one we could compute the last one as $P(S_t=N)=1-P(S_t=1)-P(S_t=2)-...-P(S_t=N-1)$ and save a few operations, but the order of the complexity is the same.\\
(In (5) the order grows linearly in t, but in (7) the order grows exponentially in t (much slower).)







